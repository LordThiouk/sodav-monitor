---
description: ðŸ“œ End-to-End (E2E) Testing Rules for Music Detection System ðŸŽµðŸ“¡
globs: *
---


These rules will guide the **E2E testing process** to ensure **accurate music detection, data integrity, and system performance** under real conditions.

---

### **ðŸ”¹ 1. General E2E Testing Principles**
âœ… **Test the entire system** â†’ Include **frontend, backend, database, APIs, and external integrations (MusicBrainz, Audd.io, Redis, PostgreSQL, etc.).**
âœ… **Use real-world scenarios** â†’ Simulate how a user interacts with the system.
âœ… **Automate tests where possible** â†’ Use tools like **Selenium, Playwright, Pytest, or Postman**.
âœ… **Monitor performance** â†’ Track **response times, detection speed, and database queries efficiency**.
âœ… **Ensure data consistency** â†’ Cross-check stored **fingerprints, play durations, detections, and reports**.

---

### **ðŸ”¹ 2. Detection Workflow Rules**
#### ðŸŽ§ **Music Detection Process**
ðŸ”¹ **Step 1: Check if it's speech or music**
   - If **speech** â†’ Ignore detection.
   - If **music** â†’ Proceed to fingerprint extraction.

ðŸ”¹ **Step 2: Perform Local Detection First**
   - Search for a match in **previously detected fingerprints**.
   - If **match found** â†’ Register the detection **without calling external APIs**.
   - If **no match** â†’ Proceed to external detection.

ðŸ”¹ **Step 3: Use MusicBrainz API**
   - If **match found** â†’ Store result with metadata.
   - If **no match** â†’ Try next detection method.

ðŸ”¹ **Step 4: Use Audd.io API**
   - If **match found** â†’ Store result.
   - If **no match** â†’ Log the failed detection for future reference.

ðŸ”¹ **Step 5: Register Detection Details**
   - Store **fingerprint** (`fingerprint`, `fingerprint_raw`) in the database.
   - Save **exact play time** (`play_duration`).
   - Record **station ID, track ID, confidence score**, and other metadata.

âœ… **Test Case:** Ensure detection **follows this sequence** and stores correct information.

---

### **ðŸ”¹ 3. Play Duration Accuracy Rules**
ðŸ”¹ **Start timestamp** â†’ Register when the track is first detected.
ðŸ”¹ **End timestamp** â†’ Register when the track stops playing.
ðŸ”¹ **Calculate exact play duration** = **End - Start**
ðŸ”¹ **Validate play duration**:
   - If **duration is less than 5 seconds**, ignore detection.
   - If **track is interrupted and resumes within 10s**, merge detections.
   - If **detection confidence is below 50%**, discard unreliable data.

âœ… **Test Case:** Validate that each **trackâ€™s play duration is correctly calculated** and stored.

---

### **ðŸ”¹ 4. Station & Streaming Validation Rules**
ðŸ”¹ **Test live radio streams** for **stability, downtime, and errors.**
ðŸ”¹ **Ensure station metadata is correctly stored** (name, region, country, URL).
ðŸ”¹ **Test recovery mechanisms** if a stream **disconnects mid-detection**.

âœ… **Test Case:** Simulate a radio stream drop and ensure **detection resumes correctly**.

---

### **ðŸ”¹ 5. Report Generation Rules**
ðŸ“Š **Test that reports contain**:
   - **Track detections per station** (with exact play duration).
   - **Top played artists & labels**.
   - **Detection confidence for each song**.
   - **Total playtime per track, artist, and station**.

ðŸ“© **Test Subscription Reports**:
   - Users should receive scheduled **daily/weekly/monthly** reports.
   - Report files must be **downloadable & correctly formatted (CSV, JSON, etc.).**
   - If an error occurs, send **error logs instead of an empty report**.

âœ… **Test Case:** Trigger reports manually and verify the **data accuracy and email delivery**.

---

### **ðŸ”¹ 6. Performance & Scalability Rules**
ðŸ”¹ **Test system load**:
   - Run **multiple detections simultaneously** across different stations.
   - Ensure PostgreSQL & Redis can handle the **increased queries**.
   - Monitor API **response times** (should be under **3 seconds**).

ðŸ”¹ **Test large dataset processing**:
   - Simulate detection on **thousands of tracks**.
   - Ensure **data retrieval (analytics, reports, dashboard stats) is optimized**.

âœ… **Test Case:** Simulate high-traffic conditions and ensure **no performance degradation**.

---

### **ðŸ”¹ 7. Database Consistency Rules**
ðŸ”¹ **Ensure no duplicate detections** for the same track & station.
ðŸ”¹ **Ensure foreign keys & relationships are enforced** (Tracks â†” Detections â†” Stations).
ðŸ”¹ **Ensure historical detection data remains intact after migrations**.

âœ… **Test Case:** Add, update, and delete tracks to confirm **database integrity**.

---

### **ðŸš€ Final Steps**
ðŸ”¹ Implement these rules in **Cursor AI** for automated validation.
ðŸ”¹ Run tests in **CI/CD pipeline** to detect regressions early.
ðŸ”¹ Log errors & notify developers if **failures occur in real-time**.

---

ðŸ’¡ **Conclusion:** These **E2E rules** will guarantee that your **music detection system works flawlessly**, detects songs accurately, and generates reliable reports **under real-world conditions**. âœ…
