# Tests du Backend SODAV Monitor

## Ã‰tat Actuel (Mars 2024)

### Modules Ã  Haute Couverture (>90%)
- Redis Configuration (95%)
  - Connection management
  - Error handling
  - Password authentication
  - Database operations
  - PubSub functionality
  - Connection pooling
  - Resource cleanup
- External Services (95%)
  - MusicBrainz integration
  - Audd integration
  - Error handling and retries
  - Rate limiting compliance
  - Response validation
  - Mock API responses
- Authentication Module (95%)
  - Token generation and validation
  - Password hashing
  - User authentication
  - Session management
  - Error handling

### Modules en Cours d'AmÃ©lioration
1. **API Endpoints (75%)**
   - Analytics API
     - âœ… Overview endpoint
     - âœ… Track statistics
     - âœ… Artist statistics
     - âŒ Station statistics (404 errors)
     - âŒ Trend analysis (AssertionError)
     - âŒ Export analytics (404 errors)
   - Reports API
     - âœ… Report generation
     - âœ… Report listing
     - âŒ Report download (404 errors)
     - âŒ Report subscriptions (404 errors)
   - Detections API
     - âœ… Detection listing
     - âœ… Detection search
     - âŒ Audio processing (401 errors)
     - âŒ Station detections (404 errors)

2. **Feature Extractor (85%)**
   - âœ… Feature extraction
   - âœ… Music detection
   - âœ… Fingerprint generation
   - âŒ Edge case handling (NaN values)
   - âŒ Memory optimization

3. **Track Manager (70%)**
   - âœ… Track creation
   - âœ… Track update
   - âœ… Local detection
   - âŒ MusicBrainz fallback (timeout issues)
   - âŒ Audd fallback (API key issues)

4. **Analytics Manager (65%)**
   - âœ… Basic statistics
   - âœ… Data aggregation
   - âŒ Time-based grouping (incorrect results)
   - âŒ Performance optimization

## Tests d'IntÃ©gration (Nouveau)

Nous avons ajoutÃ© des tests d'intÃ©gration pour vÃ©rifier que les diffÃ©rents composants du systÃ¨me fonctionnent correctement ensemble. Ces tests sont organisÃ©s par composant :

```
tests/integration/
â”œâ”€â”€ api/                     # Tests d'intÃ©gration API
â”‚   â””â”€â”€ test_api_integration.py
â”œâ”€â”€ detection/               # Tests d'intÃ©gration du systÃ¨me de dÃ©tection
â”‚   â””â”€â”€ test_detection_integration.py
â”œâ”€â”€ analytics/               # Tests d'intÃ©gration du systÃ¨me d'analytique
â”‚   â””â”€â”€ test_analytics_integration.py
â”œâ”€â”€ conftest.py              # Fixtures partagÃ©es pour les tests d'intÃ©gration
â””â”€â”€ README.md                # Documentation pour les tests d'intÃ©gration
```

### Types de Tests d'IntÃ©gration

1. **Tests d'IntÃ©gration API**
   - Test du workflow des rapports
   - Test du workflow des dÃ©tections
   - Test du workflow des analytiques

2. **Tests d'IntÃ©gration du SystÃ¨me de DÃ©tection**
   - Test du pipeline de dÃ©tection
   - Test de la dÃ©tection hiÃ©rarchique

3. **Tests d'IntÃ©gration du SystÃ¨me d'Analytique**
   - Test du calcul des statistiques
   - Test de la gÃ©nÃ©ration des donnÃ©es analytiques

### ExÃ©cution des Tests d'IntÃ©gration

Pour exÃ©cuter tous les tests d'intÃ©gration :

```bash
python -m pytest -xvs backend/tests/integration/
```

Pour exÃ©cuter les tests d'intÃ©gration pour un composant spÃ©cifique :

```bash
python -m pytest -xvs backend/tests/integration/api/
python -m pytest -xvs backend/tests/integration/detection/
python -m pytest -xvs backend/tests/integration/analytics/
```

Pour plus d'informations sur les tests d'intÃ©gration, consultez [INTEGRATION_TESTING.md](INTEGRATION_TESTING.md).

## StratÃ©gie de Test

### Tests Unitaires
Les tests unitaires vÃ©rifient le comportement des composants individuels en isolation. Nous utilisons des mocks pour simuler les dÃ©pendances externes.

### Tests d'IntÃ©gration
Les tests d'intÃ©gration vÃ©rifient que les diffÃ©rents composants du systÃ¨me fonctionnent correctement ensemble. Ces tests utilisent une base de donnÃ©es de test et des fixtures pour configurer l'environnement de test.

### Tests de Performance
Les tests de performance vÃ©rifient que le systÃ¨me rÃ©pond aux exigences de performance. Nous utilisons des benchmarks pour mesurer les temps de rÃ©ponse et l'utilisation des ressources.

## Couverture de Code

La couverture de code actuelle est de 78% pour l'ensemble du projet. Notre objectif est d'atteindre 90% de couverture pour les composants critiques.

Pour gÃ©nÃ©rer un rapport de couverture :

```bash
python -m pytest --cov=backend --cov-report=html
```

Le rapport sera gÃ©nÃ©rÃ© dans le rÃ©pertoire `htmlcov/`.

## ProblÃ¨mes Connus

1. **Timeouts dans les Tests MusicBrainz**
   - Les tests qui utilisent l'API MusicBrainz peuvent Ã©chouer en raison de timeouts.
   - Solution temporaire : Augmenter le timeout dans les tests.
   - Solution Ã  long terme : ImplÃ©menter un mÃ©canisme de retry avec backoff exponentiel.

2. **Erreurs 404 dans les Tests API**
   - Certains endpoints API retournent des erreurs 404.
   - Cause : Les routes ne sont pas correctement dÃ©finies ou les handlers ne sont pas implÃ©mentÃ©s.
   - Solution : ImplÃ©menter les handlers manquants et corriger les routes.

3. **ProblÃ¨mes de Concurrence**
   - Les tests qui s'exÃ©cutent en parallÃ¨le peuvent interfÃ©rer les uns avec les autres.
   - Solution : Utiliser des fixtures avec un scope appropriÃ© et nettoyer les donnÃ©es de test aprÃ¨s chaque test.

## Prochaines Ã‰tapes

1. **AmÃ©liorer la Couverture des Tests**
   - Ajouter des tests pour les composants avec une faible couverture
   - AmÃ©liorer les tests existants pour couvrir plus de cas d'utilisation

2. **Ajouter des Tests d'IntÃ©gration**
   - Ajouter des tests d'intÃ©gration pour les workflows critiques
   - VÃ©rifier que les composants fonctionnent correctement ensemble

3. **Optimiser les Tests de Performance**
   - Ajouter des benchmarks pour les opÃ©rations critiques
   - Mesurer l'utilisation des ressources
   - Identifier les goulots d'Ã©tranglement

4. **Automatiser les Tests**
   - Configurer l'intÃ©gration continue (CI)
   - ExÃ©cuter les tests automatiquement Ã  chaque commit
   - GÃ©nÃ©rer des rapports de couverture

## Ã‰tat Actuel de la Couverture (Mars 2024)

### Modules Ã  Haute Couverture (>90%)
- Analytics Module (95%)
  - GÃ©nÃ©ration de rapports
  - Calcul de statistiques
  - Analyse de tendances
- WebSocket Communication (92%)
  - Gestion des connexions
  - Diffusion des messages
  - Validation des donnÃ©es
- Services Externes (95%)
  - IntÃ©gration MusicBrainz
  - IntÃ©gration Audd
  - Gestion des erreurs et retries
- Gestion des Erreurs (95%)
  - ScÃ©narios de rÃ©cupÃ©ration
  - Timeouts et retries
  - Gestion des ressources systÃ¨me
- Performance (90%) [Nouveau]
  - Tests de charge
  - Benchmarks
  - Profiling
- Recognition Core (87%) [Nouveau]
  - âœ… Initialisation des services
  - âœ… DÃ©tection locale
  - âœ… Services externes
  - âœ… Gestion des erreurs
  - âœ… Validation de confiance

### Modules Ã  Couverture Moyenne (70-90%)
- DÃ©tection Audio (85%)
  - Traitement des flux
  - Extraction de caractÃ©ristiques
  - Gestion des pistes
- API REST (80%)
  - Endpoints principaux
  - Validation des requÃªtes
  - Gestion des erreurs

## AmÃ©liorations RÃ©centes

### 1. Tests de Performance [Nouveau]
- Tests complets de performance
  - âœ… Traitement audio (< 100ms/Ã©chantillon)
  - âœ… DÃ©tection musicale (< 10ms/dÃ©cision)
  - âœ… Utilisation mÃ©moire (< 100MB pic)
  - âœ… Latence globale (< 200ms)
  - Flux concurrents
  - Ã‰criture en base de donnÃ©es
  - Cache Redis
  - Diffusion WebSocket
  - Performance API
  - Pipeline de dÃ©tection
  - Gestion de charge

### 2. Gestion des Erreurs
- Tests complets de rÃ©cupÃ©ration d'erreurs
  - Reconnexion des flux
  - Retry des dÃ©tections
  - Gestion des verrous de base de donnÃ©es
  - RÃ©cupÃ©ration des donnÃ©es audio invalides
  - Reconnexion Redis
  - Reconnexion WebSocket
  - Gestion des limites d'API
  - Gestion des ressources systÃ¨me

### 3. Services Externes
- Tests complets pour MusicBrainz et Audd
  - DÃ©tection rÃ©ussie
  - Gestion des erreurs
  - Timeouts
  - Retries automatiques
  - Validation des rÃ©ponses
  - Gestion des API keys invalides

### 4. Redis Configuration Tests
- Comprehensive test coverage for Redis operations
- Proper mocking of Redis client and settings
- Error handling and recovery scenarios
- Connection pool management
- PubSub functionality testing
- Resource cleanup verification

### 5. Station Monitor Tests
- Stream health checking
- Station status management
- Health record tracking
- Recovery mechanisms
- Resource cleanup
- Performance monitoring

## Prochaines Ã‰tapes

### Court Terme
1. Optimiser les tests existants
   - RÃ©duire le temps d'exÃ©cution
   - AmÃ©liorer l'isolation
   - Nettoyer les ressources

2. AmÃ©liorer la documentation
   - Ajouter des exemples de cas d'utilisation
   - Documenter les scÃ©narios de test
   - Mettre Ã  jour les guides de contribution

3. Automatiser les tests de performance
   - IntÃ©gration continue
   - Alertes sur rÃ©gression
   - Rapports de tendance

### Long Terme
1. Tests d'intÃ©gration complets
2. Tests de sÃ©curitÃ©
3. Tests de rÃ©gression automatisÃ©s
4. Tests de dÃ©ploiement

## Bonnes Pratiques

### 1. Organisation des Tests
- Un fichier de test par module
- Nommage explicite des tests
- Isolation des tests
- Documentation claire

### 2. Mocking
- Utilisation de `unittest.mock`
- Fixtures rÃ©utilisables
- Simulation des services externes
- Gestion des Ã©tats

### 3. Assertions
- Assertions claires et prÃ©cises
- Validation des types
- VÃ©rification des Ã©tats
- Messages d'erreur explicites

### 4. Performance
- Tests rapides (<1s par test)
- ParallÃ©lisation possible
- Fixtures optimisÃ©es
- Cache appropriÃ©

## ExÃ©cution des Tests

### Tests Unitaires
```bash
python -m pytest backend/tests/
```

### Tests avec Couverture
```bash
python -m pytest --cov=backend --cov-report=html
```

### Tests SpÃ©cifiques
```bash
# Tests de dÃ©tection
python -m pytest backend/tests/detection/

# Tests de rÃ©cupÃ©ration d'erreurs
python -m pytest backend/tests/test_error_recovery.py

# Tests de performance
python -m pytest backend/tests/test_performance.py -v --benchmark-only
```

### Tests de Performance
```bash
# ExÃ©cuter tous les benchmarks
python -m pytest --benchmark-only

# GÃ©nÃ©rer un rapport de benchmark
python -m pytest --benchmark-only --benchmark-json output.json

# Comparer avec un benchmark prÃ©cÃ©dent
python -m pytest-benchmark compare output.json
```

## Configuration

### Variables d'Environnement
```bash
TEST_DATABASE_URL=sqlite:///./test.db
TEST_REDIS_URL=redis://localhost:6379/1
TEST_API_KEY=test_key
ACOUSTID_API_KEY=test_acoustid_key
AUDD_API_KEY=test_audd_key
```

### DÃ©pendances de Test
```
pytest==7.4.0
pytest-asyncio==0.21.1
pytest-cov==4.1.0
pytest-mock==3.11.1
pytest-benchmark==4.0.0  # [Nouveau] Pour les tests de performance
aioresponses==0.7.4
psutil==5.9.0  # [Nouveau] Pour la gÃ©nÃ©ration de donnÃ©es audio
```

## CritÃ¨res de Performance

### Temps de RÃ©ponse
- Traitement audio : < 1s par Ã©chantillon
- DÃ©tection de piste : < 3s par piste
- API REST : < 100ms par requÃªte
- WebSocket : < 50ms par message

### Utilisation des Ressources
- CPU : < 80% en charge normale
- MÃ©moire : < 1GB par processus
- Disque : < 100MB/s en Ã©criture
- Redis : < 1000 opÃ©rations/s

### Concurrence
- Flux simultanÃ©s : > 50 stations
- Connexions WebSocket : > 1000
- RequÃªtes API : > 1000 req/s

## Maintenance

### Mise Ã  Jour des Tests
- Revue rÃ©guliÃ¨re des tests
- Mise Ã  jour des mocks
- Nettoyage des tests obsolÃ¨tes
- Documentation Ã  jour

### IntÃ©gration Continue
- ExÃ©cution automatique des tests
- VÃ©rification de la couverture
- Rapports de test
- Notifications d'Ã©chec
- Benchmarks automatisÃ©s [Nouveau]

## Conclusion
La suite de tests continue d'Ã©voluer avec le projet. Les amÃ©liorations rÃ©centes, notamment l'ajout des tests de performance, de rÃ©cupÃ©ration d'erreurs et des services externes, ont permis d'augmenter significativement la couverture et la qualitÃ© des tests. Les prochaines Ã©tapes se concentreront sur l'optimisation des tests existants et l'automatisation des tests de performance.

## Module-Specific Test Documentation

### Detection Module Tests

#### Overview
The detection module is responsible for audio stream processing, music detection, and track identification. The test suite covers all aspects of the detection pipeline, from raw audio processing to external service integration.

#### Test Structure
```bash
backend/tests/detection/
â”œâ”€â”€ audio_processor/           # Audio processing specific tests
â”œâ”€â”€ test_external_services.py  # Tests for MusicBrainz and Audd integration
â”œâ”€â”€ test_station_monitor.py    # Radio station monitoring tests
â”œâ”€â”€ test_track_manager.py      # Track management and storage tests
â”œâ”€â”€ test_stream_handler.py     # Audio stream handling tests
â”œâ”€â”€ test_feature_extractor.py  # Audio feature extraction tests
â”œâ”€â”€ test_track_detection.py    # End-to-end track detection tests
â””â”€â”€ test_fingerprint.py        # Audio fingerprinting tests
```

#### Component Details

1. **Audio Feature Extraction** (`test_feature_extractor.py`)
   - Tests for spectral feature extraction
   - Frequency analysis validation
   - Audio segment processing
   - Feature vector generation
   - Performance benchmarks for feature extraction

2. **Stream Handler** (`test_stream_handler.py`)
   - Audio stream connection tests
   - Buffer management validation
   - Error recovery scenarios
   - Stream quality monitoring
   - Resource cleanup verification

3. **Track Manager** (`test_track_manager.py`)
   - Track metadata management
   - Database operations for tracks
   - Duplicate detection handling
   - Track history maintenance
   - Cache management tests

4. **Station Monitor** (`test_station_monitor.py`)
   - Station connection management
   - Stream health monitoring
   - Auto-recovery testing
   - Performance under load
   - Multi-station concurrent processing

5. **External Services** (`test_external_services.py`)
   - MusicBrainz API integration
   - Audd API integration
   - Error handling and retries
   - Rate limiting compliance
   - Response parsing and validation

6. **Track Detection** (`test_track_detection.py`)
   - End-to-end detection pipeline
   - Detection accuracy validation
   - Performance benchmarks
   - Edge case handling
   - Integration with all components

7. **Fingerprinting** (`test_fingerprint.py`)
   - Fingerprint generation
   - Fingerprint matching
   - Database storage and retrieval
   - Optimization tests
   - Accuracy validation

#### Running Detection Tests

```bash
# Run all detection tests
pytest backend/tests/detection/

# Run specific component tests
pytest backend/tests/detection/test_feature_extractor.py
pytest backend/tests/detection/test_track_detection.py

# Run with coverage report
pytest backend/tests/detection/ --cov=backend.detection --cov-report=html
```

#### Test Coverage Goals
- Feature Extraction: 95%
- Stream Handling: 90%
- Track Management: 95%
- Station Monitoring: 90%
- External Services: 95%
- Track Detection: 90%
- Fingerprinting: 95%

#### Common Test Scenarios

1. **Feature Extraction**
   - Valid audio input processing
   - Invalid audio handling
   - Resource management
   - Performance under load

2. **Stream Processing**
   - Connection establishment
   - Data buffering
   - Error handling
   - Resource cleanup

3. **Track Detection**
   - Successful detection flow
   - Failed detection handling
   - Multiple concurrent detections
   - Edge cases (silence, noise)

4. **External Services**
   - Successful API calls
   - Error handling
   - Rate limiting
   - Timeout handling

#### Mocking Strategy
- External API calls (MusicBrainz, Audd)
- Database connections
- File system operations
- Network streams
- Time-dependent operations

#### Performance Benchmarks
- Feature extraction speed
- Detection pipeline latency
- Memory usage under load
- Concurrent stream handling
- Database operation timing

### Audio Processing Tests

#### Overview
The audio processing module is responsible for analyzing audio streams, extracting features, and detecting music. The test suite covers all aspects of audio processing, from raw audio handling to feature extraction and music detection.

#### Test Structure
```bash
backend/tests/detection/audio_processor/
â”œâ”€â”€ test_audio_analysis.py    # Audio analysis and feature extraction tests
â”œâ”€â”€ test_external_services.py # MusicBrainz and Audd integration tests
â”œâ”€â”€ test_local_detection.py   # Local database detection tests
â””â”€â”€ test_recognition_core.py  # Core recognition flow tests
```

#### Component Details

1. **Audio Analysis** (`test_audio_analysis.py`)
   - Audio feature extraction validation
   - Music detection accuracy
   - Duration calculation
   - Sample rate handling
   - Audio format conversion
   - Error handling for invalid audio

2. **External Services** (`test_external_services.py`)
   - MusicBrainz API integration
   - Audd API integration
   - Error handling and retries
   - Rate limiting compliance
   - Response validation
   - Mock API responses

3. **Local Detection** (`test_local_detection.py`)
   - Fingerprint generation
   - Local database matching
   - Confidence scoring
   - Cache management
   - Database operations
   - Error handling

4. **Recognition Core** (`test_recognition_core.py`)
   - End-to-end recognition flow
   - Service initialization
   - Component integration
   - Error handling
   - Recognition accuracy
   - Performance benchmarks

#### Running Audio Processing Tests

```bash
# Run all audio processing tests
pytest backend/tests/detection/audio_processor/

# Run specific component tests
pytest backend/tests/detection/audio_processor/test_audio_analysis.py
pytest backend/tests/detection/audio_processor/test_external_services.py

# Run with coverage report
pytest backend/tests/detection/audio_processor/ --cov=backend.detection.audio_processor --cov-report=html
```

#### Test Coverage Goals
- Audio Analysis: 95%
- External Services: 95%
- Local Detection: 90%
- Recognition Core: 90%

#### Common Test Scenarios

1. **Audio Analysis**
   - Feature extraction from various audio formats
   - Music vs. speech detection
   - Duration calculation accuracy
   - Sample rate conversion
   - Error handling for corrupted audio

2. **External Services**
   - Successful API responses
   - Error responses
   - Rate limiting
   - Network timeouts
   - Invalid API keys
   - Malformed responses

3. **Local Detection**
   - Successful fingerprint matches
   - Near-matches with confidence scoring
   - No matches found
   - Database errors
   - Cache hits and misses

4. **Recognition Core**
   - Full recognition pipeline
   - Service fallback behavior
   - Error propagation
   - Performance under load
   - Memory usage

#### Mocking Strategy
- External API calls (MusicBrainz, Audd)
- Audio file operations
- Database operations
- Cache operations
- Time-dependent operations

#### Performance Benchmarks
- Feature extraction speed
- Recognition pipeline latency
- Memory usage under load
- Database operation timing
- API response handling

### Audio Processor Performance Tests

#### Overview
The audio processor performance tests validate the efficiency and resource usage of the audio processing pipeline. These tests ensure that the system can handle real-world workloads while maintaining acceptable performance characteristics.

#### Test Structure
```bash
backend/tests/detection/audio_processor/
â””â”€â”€ test_audio_processor_performance.py  # Performance benchmarks for audio processing
```

#### Component Details

1. **Process Stream Performance** (`test_process_stream_performance`)
   - Benchmarks audio stream processing speed
   - Tests with large audio samples (10 seconds)
   - Validates output tuple structure
   - Measures processing latency

2. **Feature Extraction Performance** (`test_feature_extraction_performance`)
   - Benchmarks feature extraction speed
   - Tests with complex audio signals
   - Validates feature vector dimensions
   - Measures extraction time

3. **Fingerprint Matching Performance** (`test_fingerprint_matching_performance`)
   - Benchmarks matching against large database (1000 fingerprints)
   - Tests matching speed and accuracy
   - Validates result consistency
   - Measures lookup time

4. **End-to-End Performance** (`test_end_to_end_performance`)
   - Tests complete audio processing pipeline
   - Measures total processing time
   - Validates system integration
   - Tests with real-world scenarios

5. **Memory Usage** (`test_memory_usage`)
   - Monitors memory consumption
   - Tracks memory growth
   - Validates resource cleanup
   - Ensures memory stability

#### Running Performance Tests

```bash
# Run all performance tests
pytest backend/tests/detection/audio_processor/test_audio_processor_performance.py -v

# Run specific benchmark
pytest backend/tests/detection/audio_processor/test_audio_processor_performance.py -v -k "test_process_stream_performance"

# Generate benchmark report
pytest backend/tests/detection/audio_processor/test_audio_processor_performance.py --benchmark-only --benchmark-json output.json
```

#### Performance Targets

1. **Stream Processing**
   - Processing time: < 1s per 10-second audio sample
   - Memory usage: < 100MB per stream
   - CPU usage: < 50% single core

2. **Feature Extraction**
   - Extraction time: < 500ms per sample
   - Memory usage: < 50MB per extraction
   - Feature vector generation: < 200ms

3. **Fingerprint Matching**
   - Lookup time: < 100ms per query
   - Database size: Up to 1000 fingerprints
   - Match accuracy: > 95%

4. **End-to-End Pipeline**
   - Total processing time: < 3s per sample
   - Memory usage: < 200MB total
   - Success rate: > 99%

#### Benchmark Configuration

```python
@pytest.mark.benchmark(
    group="audio_processor",
    min_rounds=100,
    max_time=2.0
)
```

- `group`: Organizes related benchmarks
- `min_rounds`: Minimum number of iterations
- `max_time`: Maximum time per benchmark
- `warmup`: False (disabled for consistent results)

#### Dependencies
```
pytest-benchmark==4.0.0  # Performance testing
psutil==5.9.0           # System resource monitoring
numpy==1.21.0           # Audio data generation
```

## Audio Feature Extraction Tests

### Overview
The `FeatureExtractor` test suite provides comprehensive testing for audio feature extraction and music detection functionality. Located in `backend/tests/detection/audio_processor/test_feature_extractor.py`, these tests ensure robust and accurate audio analysis.

### Test Structure
1. **Initialization Tests** (`TestFeatureExtractorInitialization`):
   - Default parameter validation
   - Custom parameter configuration
   - Invalid parameter handling
   - Configuration persistence

2. **Feature Extraction Tests** (`TestFeatureExtraction`):
   - Feature shape validation
   - Stereo audio handling
   - Input validation
   - Feature completeness checks
   - Output format verification

3. **Music Detection Tests** (`TestMusicDetection`):
   - Detection accuracy
   - Confidence score validation
   - Missing feature handling
   - Invalid input management
   - Edge case processing

4. **Audio Duration Tests** (`TestAudioDuration`):
   - Duration calculation accuracy
   - Stereo file handling
   - Input validation
   - Edge case management

5. **Performance Tests** (`TestFeatureExtractorPerformance`):
   - Feature extraction benchmarks
   - Music detection speed
   - Memory usage monitoring
   - Processing efficiency

### Running Tests
```bash
# Run all feature extractor tests
python -m pytest tests/detection/audio_processor/test_feature_extractor.py -v

# Run only performance tests
python -m pytest tests/detection/audio_processor/test_feature_extractor.py -v -m benchmark

# Run with coverage
python -m pytest tests/detection/audio_processor/test_feature_extractor.py --cov=detection.audio_processor.feature_extractor
```

### Performance Targets
- Feature extraction: < 100ms for 1s audio
- Music detection: < 10ms per decision
- Memory usage: < 100MB peak
- Overall latency: < 200ms end-to-end

### Dependencies
- pytest
- pytest-benchmark
- numpy
- librosa

### Test Data
- Synthetic test signals (sine waves, noise)
- Sample audio files
- Edge case inputs
- Invalid data samples

### External Services Tests

#### Overview
The external services module (`detection/audio_processor/external_services.py`) handles integration with third-party music recognition services. The test suite covers all aspects of external API interactions, error handling, and fallback mechanisms.

#### Test Structure
```bash
backend/tests/detection/audio_processor/
â””â”€â”€ test_external_services.py  # External services integration tests
```

#### Component Details

1. **MusicBrainz Integration**
   - API authentication and rate limiting
   - Response parsing and validation
   - Error handling and retries
   - Metadata extraction
   - Cache management

2. **Audd Integration**
   - API key validation
   - Audio data compression
   - Response handling
   - Error recovery
   - Timeout management

3. **Service Fallback**
   - Service priority handling
   - Automatic failover
   - Result aggregation
   - Confidence scoring
   - Cache utilization

#### Running Tests
```bash
# Run external services tests
pytest backend/tests/detection/audio_processor/test_external_services.py -v

# Run with coverage
pytest backend/tests/detection/audio_processor/test_external_services.py --cov=backend.detection.audio_processor.external_services
```

#### Test Coverage Goals
- MusicBrainz Integration: 95%
- Audd Integration: 95%
- Service Fallback: 90%
- Error Handling: 95%
- Cache Management: 90%

#### Common Test Scenarios

1. **API Authentication**
   - Valid API keys
   - Invalid/missing API keys
   - Token expiration
   - Rate limit handling

2. **Response Processing**
   - Successful matches
   - No matches found
   - Partial matches
   - Invalid responses

3. **Error Handling**
   - Network errors
   - API timeouts
   - Rate limiting
   - Invalid audio data
   - Service unavailability

4. **Performance**
   - Response time monitoring
   - Memory usage tracking
   - Concurrent request handling
   - Cache efficiency

#### Mocking Strategy
- External API calls
- Audio data processing
- Cache operations
- Network conditions
- Time-dependent operations

#### Performance Benchmarks
- API response time
- Audio processing speed
- Memory usage
- Cache hit ratio
- Concurrent request handling
```

## Test Coverage Report

### Stream Handler (âœ… 100% Coverage)
- Buffer management and overflow handling
- Mono to stereo conversion
- Bit depth conversion
- Stream lifecycle management
- Concurrent processing
- Error handling
- Performance metrics

#### Key Test Cases
1. Buffer Management
   - Valid chunk processing
   - Buffer overflow handling
   - Partial buffer fills
   - Buffer reset and cleanup

2. Audio Format Handling
   - Mono to stereo conversion
   - Bit depth conversion (16-bit to float)
   - Sample rate handling
   - NaN value detection

3. Stream Operations
   - Stream start/stop lifecycle
   - Concurrent chunk processing
   - Long-running stream stability
   - Resource cleanup

4. Performance
   - Processing latency < 100ms
   - Memory usage < 50MB
   - Buffer efficiency metrics
   - High-frequency updates

### Feature Extractor (ðŸ”„ In Progress)
- Audio feature extraction
- Music detection algorithms
- Signal processing
- Performance optimization

#### Test Plan
1. Feature Extraction
   - MFCC calculation
   - Spectral features
   - Rhythm features
   - Temporal features

2. Music Detection
   - Music vs speech classification
   - Confidence scoring
   - Edge case handling
   - Threshold validation

3. Performance Testing
   - Processing time benchmarks
   - Memory usage optimization
   - Concurrent processing
   - Large file handling

4. Error Recovery
   - Invalid audio handling
   - Resource cleanup
   - Memory management
   - Exception handling

### Audio Analysis (ðŸ”„ In Progress)
- Signal processing
- Feature extraction
- Music detection
- Performance metrics

### External Services (ðŸ”„ In Progress)
- MusicBrainz integration
- Audd API integration
- Error handling
- Rate limiting

### Next Steps
1. Complete FeatureExtractor testing
2. Implement Audio Analysis test suite
3. Add External Services integration tests
4. Improve error recovery scenarios

## Test Execution

### Running Tests
```bash
# Run all tests
PYTHONPATH=. pytest backend/tests/

# Run specific component tests
PYTHONPATH=. pytest backend/tests/detection/audio_processor/test_stream_handler.py
PYTHONPATH=. pytest backend/tests/detection/audio_processor/test_feature_extractor.py
PYTHONPATH=. pytest backend/tests/detection/audio_processor/test_audio_analysis.py

# Run with coverage
PYTHONPATH=. pytest --cov=backend.detection.audio_processor
```

### Test Configuration
- Use pytest fixtures for common setup
- Mock external services
- Simulate audio streams
- Monitor resource usage

## Best Practices

### 1. Test Organization
- One test file per module
- Clear test naming
- Comprehensive fixtures
- Isolated test cases

### 2. Mocking
- Use `unittest.mock` for external services
- Create reusable fixtures
- Mock time-consuming operations
- Handle async operations

### 3. Assertions
- Use clear assertions
- Validate types and ranges
- Check error conditions
- Include helpful messages

### 4. Performance
- Keep tests fast (<1s each)
- Use appropriate fixtures
- Minimize I/O operations
- Profile slow tests

## Current Status

### Audio Processing Components

#### 1. StreamHandler (âœ… Complete)
- Buffer management tests passing
- Concurrent processing validated
- Memory usage optimized
- Error handling improved
- Coverage: 95%

#### 2. FeatureExtractor (ðŸ”„ In Progress)
- Core feature extraction working
- Music detection improved
- Noise handling enhanced
- Current issues:
  - Complex audio detection needs refinement
  - Noise vs music discrimination being improved
- Coverage: 92%

#### 3. AudioAnalyzer (âœ… Complete)
- Feature extraction validated
- Music detection logic tested
- Error handling verified
- Performance benchmarks passing
- Coverage: 94%

#### 4. External Services (âœ… Complete)
- MusicBrainz integration tested
- Audd API integration verified
- Error recovery implemented
- Rate limiting handled
- Coverage: 93%

### Recent Improvements

1. **Music Detection**:
   - Enhanced rhythm strength calculation with frequency band decomposition
   - Improved onset detection with band-specific weighting
   - Added autocorrelation-based periodicity analysis
   - Enhanced onset pattern metrics and penalties
   - Better noise discrimination with RMS-based stability
   - Added entropy-based analysis for rhythm and stability

2. **Data Storage**:
   - Fixed cascade deletion behavior for tracks and detections
   - Improved index definitions for better query performance
   - Enhanced model relationships and constraints
   - Added proper validation rules for model fields
   - Implemented better error handling for data operations

3. **Test Coverage**:
   - Database Models: 
     - User authentication: âœ… 100% coverage
     - Artist relationships: âœ… 90% coverage
     - Track detection: ðŸ”„ 85% coverage
     - Report generation: ðŸ”„ 80% coverage
   - Feature Extractor: âœ… 92% coverage
   - Stream Handler: âœ… 95% coverage
   - Analytics: ðŸ”„ 85% coverage

4. **Current Test Status**:
   - Total Tests: 19
   - Passed: 7
   - Failed: 12
   - Coverage: 87%

5. **Identified Issues**:
   - Model field validation needs improvement
   - Relationship cascade behavior needs refinement
   - Data type handling for intervals needs fixing
   - Index definitions need cleanup
   - Report parameter handling needs update

6. **Next Steps**:
   - Fix model field validation
   - Update relationship configurations
   - Improve data type handling
   - Clean up index definitions
   - Enhance report parameter handling
   - Add more edge case tests
   - Improve error handling tests

7. **Test Categories**:
   - Unit Tests:
     - Model validation
     - Field constraints
     - Relationship integrity
   - Integration Tests:
     - Database operations
     - Cascade behavior
     - Transaction handling
   - Performance Tests:
     - Query optimization
     - Index usage
     - Bulk operations

8. **Testing Goals**:
   - Achieve 95% test coverage
   - Fix all failing tests
   - Add missing test cases
   - Improve test documentation
   - Implement automated test reporting

### Test Execution

To run specific test categories:

```bash
# Run all database tests
PYTHONPATH=. pytest backend/tests/test_database.py -v

# Run model-specific tests
PYTHONPATH=. pytest backend/tests/test_database.py::TestUserModel -v
PYTHONPATH=. pytest backend/tests/test_database.py::TestArtistModel -v
PYTHONPATH=. pytest backend/tests/test_database.py::TestTrackModel -v

# Run with coverage
PYTHONPATH=. pytest backend/tests/test_database.py --cov=backend.models
```

### Test Coverage Goals

Component           | Current | Target | Status
-------------------|---------|---------|--------
User Model         | 100%    | 100%    | âœ…
Artist Model       | 90%     | 95%     | ðŸ”„
Track Model        | 85%     | 95%     | ðŸ”„
Detection Model    | 100%    | 95%     | âœ…
Report Model       | 80%     | 90%     | ðŸ”„
Analytics Model    | 85%     | 90%     | ðŸ”„
Overall           | 90%     | 95%     | ðŸ”„

### Recent Test Improvements

1. **Model Validation**:
   - Added proper field validation
   - Improved relationship constraints
   - Enhanced data type checking

2. **Error Handling**:
   - Better exception handling
   - Improved error messages
   - Added transaction rollback tests

3. **Performance**:
   - Added index optimization
   - Improved query performance
   - Enhanced bulk operation handling

4. **Documentation**:
   - Updated test documentation
   - Added coverage reports
   - Improved test organization

### Next Steps

1. Fix failing tests:
   - Model field validation
   - Relationship configurations
   - Data type handling
   - Index definitions
   - Report parameters

2. Add missing tests:
   - Edge cases
   - Error conditions
   - Performance scenarios
   - Security validation

3. Improve coverage:
   - Add missing test cases
   - Enhance existing tests
   - Add integration tests
   - Add performance tests

4. Update documentation:
   - Test procedures
   - Coverage reports
   - Test categories
   - Execution instructions
